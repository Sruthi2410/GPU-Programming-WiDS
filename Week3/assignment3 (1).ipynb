{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T16:26:32.607373Z","iopub.execute_input":"2025-12-30T16:26:32.607997Z","iopub.status.idle":"2025-12-30T16:26:32.776496Z","shell.execute_reply.started":"2025-12-30T16:26:32.607978Z","shell.execute_reply":"2025-12-30T16:26:32.775781Z"}},"outputs":[{"name":"stdout","text":"Tue Dec 30 16:26:32 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T16:27:00.422740Z","iopub.execute_input":"2025-12-30T16:27:00.423275Z","iopub.status.idle":"2025-12-30T16:27:00.586984Z","shell.execute_reply.started":"2025-12-30T16:27:00.423245Z","shell.execute_reply":"2025-12-30T16:27:00.586288Z"}},"outputs":[{"name":"stdout","text":"Tue Dec 30 16:27:00 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%%writefile coalesced.cu\n#include <iostream>\n#include <cuda_runtime.h>\n\n__global__ void coalesced(float* a, float* b, float* c, int n) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < n) {\n        c[idx] = a[idx] + b[idx];\n    }\n}\n\nint main() {\n    int n = 1 << 24;  // ~16 million\n    size_t size = n * sizeof(float);\n\n    float *h_a = new float[n];\n    float *h_b = new float[n];\n\n    for (int i = 0; i < n; i++) {\n        h_a[i] = i;\n        h_b[i] = 2 * i;\n    }\n\n    float *d_a, *d_b, *d_c;\n    cudaMalloc(&d_a, size);\n    cudaMalloc(&d_b, size);\n    cudaMalloc(&d_c, size);\n\n    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n\n    int blockSize = 256;\n    int gridSize = (n + blockSize - 1) / blockSize;\n\n    // Warm-up\n    coalesced<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n    cudaDeviceSynchronize();\n\n    cudaEvent_t start, stop;\n    cudaEventCreate(&start);\n    cudaEventCreate(&stop);\n\n    cudaEventRecord(start);\n    for (int i = 0; i < 10; i++) {\n        coalesced<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n    }\n    cudaEventRecord(stop);\n    cudaEventSynchronize(stop);\n\n    float ms;\n    cudaEventElapsedTime(&ms, start, stop);\n\n    std::cout << \"Coalesced time (avg over 10 runs): \"\n              << ms / 10 << \" ms\\n\";\n\n    return 0;\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T16:54:43.372582Z","iopub.execute_input":"2025-12-30T16:54:43.373441Z","iopub.status.idle":"2025-12-30T16:54:43.379453Z","shell.execute_reply.started":"2025-12-30T16:54:43.373404Z","shell.execute_reply":"2025-12-30T16:54:43.378725Z"}},"outputs":[{"name":"stdout","text":"Overwriting coalesced.cu\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!nvcc coalesced.cu -o coalesced\n!./coalesced\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T16:54:55.528825Z","iopub.execute_input":"2025-12-30T16:54:55.529557Z","iopub.status.idle":"2025-12-30T16:54:57.756627Z","shell.execute_reply.started":"2025-12-30T16:54:55.529528Z","shell.execute_reply":"2025-12-30T16:54:57.755680Z"}},"outputs":[{"name":"stdout","text":"Coalesced time (avg over 10 runs): 0.365443 ms\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"%%writefile non_coalesced.cu\n#include <iostream>\n#include <cuda_runtime.h>\n\n#define STRIDE 32\n\n__global__ void non_coalesced(float* a, float* b, float* c, int n) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < n) {\n        int access = (idx * STRIDE) % n;  // scattered access\n        c[access] = a[access] + b[access];\n    }\n}\n\nint main() {\n    int n = 1 << 24;\n    size_t size = n * sizeof(float);\n\n    float *h_a = new float[n];\n    float *h_b = new float[n];\n\n    for (int i = 0; i < n; i++) {\n        h_a[i] = i;\n        h_b[i] = 2 * i;\n    }\n\n    float *d_a, *d_b, *d_c;\n    cudaMalloc(&d_a, size);\n    cudaMalloc(&d_b, size);\n    cudaMalloc(&d_c, size);\n\n    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n\n    int blockSize = 256;\n    int gridSize = (n + blockSize - 1) / blockSize;\n\n    // Warm-up\n    non_coalesced<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n    cudaDeviceSynchronize();\n\n    cudaEvent_t start, stop;\n    cudaEventCreate(&start);\n    cudaEventCreate(&stop);\n\n    cudaEventRecord(start);\n    for (int i = 0; i < 10; i++) {\n        non_coalesced<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n    }\n    cudaEventRecord(stop);\n    cudaEventSynchronize(stop);\n\n    float ms;\n    cudaEventElapsedTime(&ms, start, stop);\n\n    std::cout << \"Non-coalesced time (avg over 10 runs): \"\n              << ms / 10 << \" ms\\n\";\n\n    return 0;\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T16:55:17.148530Z","iopub.execute_input":"2025-12-30T16:55:17.149092Z","iopub.status.idle":"2025-12-30T16:55:17.154897Z","shell.execute_reply.started":"2025-12-30T16:55:17.149057Z","shell.execute_reply":"2025-12-30T16:55:17.154282Z"}},"outputs":[{"name":"stdout","text":"Overwriting non_coalesced.cu\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!nvcc non_coalesced.cu -o non_coalesced\n!./non_coalesced\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T16:55:21.551468Z","iopub.execute_input":"2025-12-30T16:55:21.552215Z","iopub.status.idle":"2025-12-30T16:55:23.858975Z","shell.execute_reply.started":"2025-12-30T16:55:21.552186Z","shell.execute_reply":"2025-12-30T16:55:23.858261Z"}},"outputs":[{"name":"stdout","text":"Non-coalesced time (avg over 10 runs): 4.7251 ms\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"%%writefile shared_memory.cu\n#include <iostream>\n#include <cuda_runtime.h>\n\n__global__ void global_kernel(float* x, float* y, int n) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx > 0 && idx < n-1)\n        y[idx] = x[idx-1] + x[idx] + x[idx+1];\n}\n\n__global__ void shared_kernel(float* x, float* y, int n) {\n    extern __shared__ float s[];\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    int t = threadIdx.x;\n\n    if (idx < n) s[t] = x[idx];\n    __syncthreads();\n\n    if (t > 0 && t < blockDim.x-1 && idx < n-1)\n        y[idx] = s[t-1] + s[t] + s[t+1];\n}\n\nint main() {\n    int n = 1 << 24;\n    size_t size = n * sizeof(float);\n\n    float *h_x = new float[n];\n    for (int i = 0; i < n; i++) h_x[i] = i;\n\n    float *d_x, *d_y;\n    cudaMalloc(&d_x, size);\n    cudaMalloc(&d_y, size);\n    cudaMemcpy(d_x, h_x, size, cudaMemcpyHostToDevice);\n\n    int blockSize = 256;\n    int gridSize = (n + blockSize - 1) / blockSize;\n\n    cudaEvent_t s, e;\n    cudaEventCreate(&s);\n    cudaEventCreate(&e);\n\n    cudaEventRecord(s);\n    global_kernel<<<gridSize, blockSize>>>(d_x, d_y, n);\n    cudaEventRecord(e);\n    cudaEventSynchronize(e);\n    float t1;\n    cudaEventElapsedTime(&t1, s, e);\n\n    cudaEventRecord(s);\n    shared_kernel<<<gridSize, blockSize, blockSize*sizeof(float)>>>(d_x, d_y, n);\n    cudaEventRecord(e);\n    cudaEventSynchronize(e);\n    float t2;\n    cudaEventElapsedTime(&t2, s, e);\n\n    std::cout << \"Global memory time: \" << t1 << \" ms\\n\";\n    std::cout << \"Shared memory time: \" << t2 << \" ms\\n\";\n    std::cout << \"Speedup: \" << t1/t2 << \"x\\n\";\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T16:29:56.411981Z","iopub.execute_input":"2025-12-30T16:29:56.412774Z","iopub.status.idle":"2025-12-30T16:29:56.418612Z","shell.execute_reply.started":"2025-12-30T16:29:56.412737Z","shell.execute_reply":"2025-12-30T16:29:56.417886Z"}},"outputs":[{"name":"stdout","text":"Writing shared_memory.cu\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!nvcc shared_memory.cu -o shared_memory\n!./shared_memory\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T16:30:15.886346Z","iopub.execute_input":"2025-12-30T16:30:15.886891Z","iopub.status.idle":"2025-12-30T16:30:18.087005Z","shell.execute_reply.started":"2025-12-30T16:30:15.886861Z","shell.execute_reply":"2025-12-30T16:30:18.086312Z"}},"outputs":[{"name":"stdout","text":"Global memory time: 16.8835 ms\nShared memory time: 0.28144 ms\nSpeedup: 59.9897x\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T18:58:40.490157Z","iopub.execute_input":"2025-12-30T18:58:40.490438Z","iopub.status.idle":"2025-12-30T18:58:40.616170Z","shell.execute_reply.started":"2025-12-30T18:58:40.490413Z","shell.execute_reply":"2025-12-30T18:58:40.614793Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: nvidia-smi: command not found\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport time\n\nH = 2048\nW = 2048\n\nimage = np.random.rand(H, W).astype(np.float32)\n\nkernel = np.array([[1, 1, 1],\n                   [1, 1, 1],\n                   [1, 1, 1]], dtype=np.float32)\n\noutput = np.zeros((H, W), dtype=np.float32)\n\nstart = time.perf_counter()\n\nfor i in range(1, H - 1):\n    for j in range(1, W - 1):\n        s = 0.0\n        for ki in range(-1, 2):\n            for kj in range(-1, 2):\n                s += kernel[ki + 1, kj + 1] * image[i + ki, j + kj]\n        output[i, j] = s\n\nend = time.perf_counter()\n\nprint(\"CPU 2D convolution time:\", end - start, \"seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T18:59:39.525133Z","iopub.execute_input":"2025-12-30T18:59:39.526460Z","iopub.status.idle":"2025-12-30T19:00:10.468157Z","shell.execute_reply.started":"2025-12-30T18:59:39.526412Z","shell.execute_reply":"2025-12-30T19:00:10.467069Z"}},"outputs":[{"name":"stdout","text":"CPU 2D convolution time: 30.864006089000043 seconds\n","output_type":"stream"}],"execution_count":2}]}